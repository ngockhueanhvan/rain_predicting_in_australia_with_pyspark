{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Rain in Australia: Predict rain tomorrow in Australia\r\n",
    "\r\n",
    "#### Developer: Anh Van\r\n",
    "#### Email: ngockhueanhvan@gmail.com\r\n",
    "Date: 30/09/2019\r\n",
    "Version: 1.0\r\n",
    "Environment: Python 3.5 and Jupyter Notebook\r\n",
    "\r\n",
    "#### Introduction:\r\n",
    "- Main purpose of this assignment is to predict probability of tomorrow rain in Australia using machine learning algorithms, including Desision Tree, Random Forest, Logistic Regression and GB Tree Classifier\r\n",
    "- The procedure including:\r\n",
    "    - Step 1: Import Spark Session and Loading data\r\n",
    "    - Step 2: Load the dataset\r\n",
    "    - Step 3: Delete columns\r\n",
    "    - Step 4: Print the number of missing data\r\n",
    "    - Step 5: Fill the missing data\r\n",
    "    - Step 6: Data transformation\r\n",
    "    - Step 7: Feature vetor and divide dataset \r\n",
    "    - Step 8: Machine learning algorithms\r\n",
    "    - Step 9: Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# function operations in Spark dataframe\r\n",
    "from pyspark.sql.functions import col, avg, when, count\r\n",
    "\r\n",
    "# convert string variables into Numeric variables for machine learning algorithms\r\n",
    "from pyspark.ml.feature import StringIndexer\r\n",
    "\r\n",
    "# convert numeric variables into double type\r\n",
    "from pyspark.sql.types import DoubleType\r\n",
    "\r\n",
    "# pipeline\r\n",
    "from pyspark.ml import Pipeline\r\n",
    "\r\n",
    "# assemble independent variables into feature vector\r\n",
    "from pyspark.ml.feature import VectorAssembler\r\n",
    "\r\n",
    "# build evaluator for model performance\r\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
    "\r\n",
    "# Decision Tree\r\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\r\n",
    "\r\n",
    "# Random Forest\r\n",
    "from pyspark.ml.classification import RandomForestClassifier\r\n",
    "\r\n",
    "# Logistic Regression\r\n",
    "from pyspark.ml.classification import LogisticRegression\r\n",
    "\r\n",
    "# Gradient Boosted Tree\r\n",
    "from pyspark.ml.classification import GBTClassifier\r\n",
    "\r\n",
    "# visualization\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part A: Creating Spark Session and Loading the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Import Spark Session and initialize Spark\n",
    "- In this section, we are going to create Spark Session, providing a single point of entry to interact with underlying Spark functionality and allowing programming Spark with Dataframe and Dataset APIs\n",
    "- The Application Name is \"Assignment 2\"\n",
    "- Spark is run locally with 4 processing cores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 pyspark-shell'\n",
    "\n",
    "# import libraries \n",
    "from pyspark import SparkConf, SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# create the SparkConf object\n",
    "spark_conf = SparkConf()\\\n",
    "    .setMaster(\"local[4]\")\n",
    "    #.set(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.11:2.4.1\")\n",
    "\n",
    "\n",
    "# local[4]: run Spark locally with 4 working processors as required.\n",
    "# The `appName` field is a name to be shown on the Sparking cluster UI. \n",
    "\n",
    "# create the SparkSession object   \n",
    "my_spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Assignment 2\")\\\n",
    "    .config(conf=spark_conf)\\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/ass_2\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/ass_2\") \\\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Load the dataset and print the schema and total number of entries\n",
    "- In this section, we are going to load a csv dataset regarding weather in Australia into dataframe using spark session\n",
    "- We are printing the schema and total number of entries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# load the data to dataframe using SparkSession\n",
    "weather = my_spark.read.csv(\"weatherAUS.csv\", header=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# print the total number of entries\n",
    "entries = weather.count()\n",
    "print(\"Total number of entries is\", entries)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of entries is 142193\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# print the dataframe schema\n",
    "weather.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- MinTemp: string (nullable = true)\n",
      " |-- MaxTemp: string (nullable = true)\n",
      " |-- Rainfall: string (nullable = true)\n",
      " |-- Evaporation: string (nullable = true)\n",
      " |-- Sunshine: string (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: string (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: string (nullable = true)\n",
      " |-- WindSpeed3pm: string (nullable = true)\n",
      " |-- Humidity9am: string (nullable = true)\n",
      " |-- Humidity3pm: string (nullable = true)\n",
      " |-- Pressure9am: string (nullable = true)\n",
      " |-- Pressure3pm: string (nullable = true)\n",
      " |-- Cloud9am: string (nullable = true)\n",
      " |-- Cloud3pm: string (nullable = true)\n",
      " |-- Temp9am: string (nullable = true)\n",
      " |-- Temp3pm: string (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Regarding the schema, we can see all of the columns of dataframe are string, which is apparently unusual. \n",
    "- For example, the MinTemp and Maxtemp are usually numeric. Let's print out the first few lines of dataframe to see the actual figures. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# show the first five lines of dataframe\n",
    "weather.show(5, truncate=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "|Date      |Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
      "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "|2008-12-01|Albury  |13.4   |22.9   |0.6     |NA         |NA      |W          |44           |W         |WNW       |20          |24          |71         |22         |1007.7     |1007.1     |8       |NA      |16.9   |21.8   |No       |No          |\n",
      "|2008-12-02|Albury  |7.4    |25.1   |0       |NA         |NA      |WNW        |44           |NNW       |WSW       |4           |22          |44         |25         |1010.6     |1007.8     |NA      |NA      |17.2   |24.3   |No       |No          |\n",
      "|2008-12-03|Albury  |12.9   |25.7   |0       |NA         |NA      |WSW        |46           |W         |WSW       |19          |26          |38         |30         |1007.6     |1008.7     |NA      |2       |21     |23.2   |No       |No          |\n",
      "|2008-12-04|Albury  |9.2    |28     |0       |NA         |NA      |NE         |24           |SE        |E         |11          |9           |45         |16         |1017.6     |1012.8     |NA      |NA      |18.1   |26.5   |No       |No          |\n",
      "|2008-12-05|Albury  |17.5   |32.3   |1       |NA         |NA      |W          |41           |ENE       |NW        |7           |20          |82         |33         |1010.8     |1006       |7       |8       |17.8   |29.7   |No       |No          |\n",
      "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We can see many of them should have been numeric, i.e. MinTemp, MaxTemp, Rainfall, etc. instead of string. \n",
    "- Thus, we might need to convert data types of certain columns in latter steps."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part B: Data Cleaning and Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Delete columns from the dataset\n",
    "- In this section, we are goin to delete some unnecessary data from the dataset to enhance efficiency and accuracy of our model\n",
    "- We are going to delete the following columns:\n",
    "    - Date\n",
    "    - Location\n",
    "    - Evaporation\n",
    "    - Sunshine\n",
    "    - Cloud9am\n",
    "    - Cloud3pm\n",
    "    - Temp9am\n",
    "    - Temp3pm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# list of columns to be deleted\n",
    "del_col = ['Date','Location', 'Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n",
    "\n",
    "# drop the above columns\n",
    "weather = weather.drop(*del_col)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# print again the schema to check\n",
    "weather.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- MinTemp: string (nullable = true)\n",
      " |-- MaxTemp: string (nullable = true)\n",
      " |-- Rainfall: string (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: string (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: string (nullable = true)\n",
      " |-- WindSpeed3pm: string (nullable = true)\n",
      " |-- Humidity9am: string (nullable = true)\n",
      " |-- Humidity3pm: string (nullable = true)\n",
      " |-- Pressure9am: string (nullable = true)\n",
      " |-- Pressure3pm: string (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Print the number of missing data in each column\n",
    "- In this section, we are going to find and print out the total number of null values in each column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# define a function to count 'NA' values for each column of the input datafram\n",
    "def number_of_na(dataset):\n",
    "    # declare the list of columns and their number of 'NA' values \n",
    "    na_list = []\n",
    "    # list of features from the dataframe\n",
    "    cols = dataset.columns\n",
    "    # for each column, count the number of 'NA' and append to the na_list()\n",
    "    for column in cols:\n",
    "        na = dataset.where(col(column)=='NA').count()\n",
    "        na_list.append((column,na))\n",
    "    return na_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# apply to our dataset\n",
    "na_list = number_of_na(weather)\n",
    "# print out the results\n",
    "for each in na_list:\n",
    "    column = each[0]\n",
    "    na = each[1]\n",
    "    print(\"- {0} has {1} null values\".format(column, na))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- MinTemp has 637 null values\n",
      "- MaxTemp has 322 null values\n",
      "- Rainfall has 1406 null values\n",
      "- WindGustDir has 9330 null values\n",
      "- WindGustSpeed has 9270 null values\n",
      "- WindDir9am has 10013 null values\n",
      "- WindDir3pm has 3778 null values\n",
      "- WindSpeed9am has 1348 null values\n",
      "- WindSpeed3pm has 2630 null values\n",
      "- Humidity9am has 1774 null values\n",
      "- Humidity3pm has 3610 null values\n",
      "- Pressure9am has 14014 null values\n",
      "- Pressure3pm has 13981 null values\n",
      "- RainToday has 1406 null values\n",
      "- RainTomorrow has 0 null values\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Fill the missing data with average value and maximum occurence value\n",
    "- In this section, we are going to fill all the missing values with:\n",
    "    - Average values for numeric columns\n",
    "    - Maximum occurences for non-numeric columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find the numeric and non-numeric features\n",
    "- First, we are going to identify which columns are numeric and none-numeric\n",
    "- Here, if the result of average function are floats, then the feature is numeric\n",
    "- Otherwise, the feature is non-numeric"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# list of all features\n",
    "all_col = weather.columns\n",
    "# list of numeric features\n",
    "numeric_col = []\n",
    "# list of none-numeric features\n",
    "none_numeric_col = []\n",
    "\n",
    "# append each list the features from dataframe\n",
    "for column in all_col:\n",
    "    # calculate the average value of each column\n",
    "    average = weather.groupby().agg(avg(column)).collect()[0][0]\n",
    "    # if we have floats, then the feature is numeric\n",
    "    if average != None:\n",
    "        numeric_col.append((column, average))\n",
    "    # elseif we have 'None', the feature is none-numeric\n",
    "    else:\n",
    "        none_numeric_col.append(column)\n",
    "\n",
    "# print the numeric list\n",
    "print(\"The numeric features are:\")\n",
    "for features in numeric_col:\n",
    "    print(\"-\", features[0])\n",
    "\n",
    "# print the none-numeric list\n",
    "print(\"\\nThe none-numeric features are:\")\n",
    "for features in none_numeric_col:\n",
    "    print(\"-\", features)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The numeric features are:\n",
      "- MinTemp\n",
      "- MaxTemp\n",
      "- Rainfall\n",
      "- WindGustSpeed\n",
      "- WindSpeed9am\n",
      "- WindSpeed3pm\n",
      "- Humidity9am\n",
      "- Humidity3pm\n",
      "- Pressure9am\n",
      "- Pressure3pm\n",
      "\n",
      "The none-numeric features are:\n",
      "- WindGustDir\n",
      "- WindDir9am\n",
      "- WindDir3pm\n",
      "- RainToday\n",
      "- RainTomorrow\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Replace 'NA' values of numeric features with average values of each feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# list of numeric features, where the first item is feature name and second item is average value\n",
    "numeric_col"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('MinTemp', 12.186399728729311),\n",
       " ('MaxTemp', 23.2267841912725),\n",
       " ('Rainfall', 2.3499740743107442),\n",
       " ('WindGustSpeed', 39.98429165757619),\n",
       " ('WindSpeed9am', 14.001988000994),\n",
       " ('WindSpeed3pm', 18.63757586179718),\n",
       " ('Humidity9am', 68.8438103105705),\n",
       " ('Humidity3pm', 51.482606091656265),\n",
       " ('Pressure9am', 1017.6537584159615),\n",
       " ('Pressure3pm', 1015.2582035378894)]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# replace the 'NA' values of numeric features with average values of each feature\n",
    "for column in numeric_col:\n",
    "    col_name = column[0]\n",
    "    avg_col = column[1]\n",
    "    weather = weather.withColumn(col_name, when(weather[col_name]=='NA',avg_col).otherwise(weather[col_name]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Replace 'NA' values of none-numeric features with the highest frequent values of each feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# list of non-numeric features\n",
    "non_col = []\n",
    "\n",
    "for column in none_numeric_col:\n",
    "    # count the occurences of each distinct word\n",
    "    # sort the results from the higest to the lowest frequency\n",
    "    aggr = weather.groupby(column).agg(count(column).alias('freq')).sort('freq', ascending=False)\n",
    "    # the highest frequent item\n",
    "    string = aggr.collect()[0][0]\n",
    "    # the occurence of the item\n",
    "    freq = aggr.collect()[0][1]\n",
    "    # append to the list\n",
    "    non_col.append((column, string, freq))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# list of non-numeric features, where the first item is feature name, \n",
    "# second item is the highest frequent word\n",
    "# third item is the frequency\n",
    "non_col"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('WindGustDir', 'W', 9780),\n",
       " ('WindDir9am', 'N', 11393),\n",
       " ('WindDir3pm', 'SE', 10663),\n",
       " ('RainToday', 'No', 109332),\n",
       " ('RainTomorrow', 'No', 110316)]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Replace 'NA' values of none-numeric features with the highest frequent values of each feature\n",
    "for column in non_col:\n",
    "    col_name = column[0]\n",
    "    highest_freq = column[1]\n",
    "    weather = weather.withColumn(col_name, when(weather[col_name]=='NA',highest_freq).otherwise(weather[col_name]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 6: Data transformation\n",
    "- In this section, we are going to transform the data so that it is ready to process by machine learning algorithm\n",
    "- Convert numeric data into double type\n",
    "- Convert non-numeric data into numbers using StringIndexer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# convert the numberic data into double using cast() function\n",
    "for column in numeric_col:\n",
    "    weather = weather.withColumn(column[0], col(column[0]).cast('double'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# convert non-numeric data into numbers using StringIndexer \n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"Index\").fit(weather) for column in none_numeric_col]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "# fit to the dataframe\n",
    "weather = pipeline.fit(weather).transform(weather)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# print schema after transformation\n",
    "weather.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- MinTemp: double (nullable = true)\n",
      " |-- MaxTemp: double (nullable = true)\n",
      " |-- Rainfall: double (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: double (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: double (nullable = true)\n",
      " |-- WindSpeed3pm: double (nullable = true)\n",
      " |-- Humidity9am: double (nullable = true)\n",
      " |-- Humidity3pm: double (nullable = true)\n",
      " |-- Pressure9am: double (nullable = true)\n",
      " |-- Pressure3pm: double (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      " |-- WindGustDirIndex: double (nullable = false)\n",
      " |-- WindDir9amIndex: double (nullable = false)\n",
      " |-- WindDir3pmIndex: double (nullable = false)\n",
      " |-- RainTodayIndex: double (nullable = false)\n",
      " |-- RainTomorrowIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# display the top five lines\n",
    "weather.show(5, False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+----------------+---------------+---------------+--------------+-----------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|WindGustDirIndex|WindDir9amIndex|WindDir3pmIndex|RainTodayIndex|RainTomorrowIndex|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+----------------+---------------+---------------+--------------+-----------------+\n",
      "|13.4   |22.9   |0.6     |W          |44.0         |W         |WNW       |20.0        |24.0        |71.0       |22.0       |1007.7     |1007.1     |No       |No          |0.0             |6.0            |7.0            |0.0           |0.0              |\n",
      "|7.4    |25.1   |0.0     |WNW        |44.0         |NNW       |WSW       |4.0         |22.0        |44.0       |25.0       |1010.6     |1007.8     |No       |No          |9.0             |9.0            |3.0            |0.0           |0.0              |\n",
      "|12.9   |25.7   |0.0     |WSW        |46.0         |W         |WSW       |19.0        |26.0        |38.0       |30.0       |1007.6     |1008.7     |No       |No          |6.0             |6.0            |3.0            |0.0           |0.0              |\n",
      "|9.2    |28.0   |0.0     |NE         |24.0         |SE        |E         |11.0        |9.0         |45.0       |16.0       |1017.6     |1012.8     |No       |No          |13.0            |1.0            |10.0           |0.0           |0.0              |\n",
      "|17.5   |32.3   |1.0     |W          |41.0         |ENE       |NW        |7.0         |20.0        |82.0       |33.0       |1010.8     |1006.0     |No       |No          |0.0             |10.0           |8.0            |0.0           |0.0              |\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+----------------+---------------+---------------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 7: Create the feature vector and divide the dataset\n",
    "- In this section, we are going to create the feature vector from the given columns\n",
    "- RainTomorrow_index should be excluded from the feature vector\n",
    "- Next, dataset is randomly split into two parts, including 70% training data and 30% testing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the feature vector from the given columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# the columns to be excluded from the feature vector\n",
    "ignore_cols = ['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow','RainTomorrowIndex']\n",
    "# Assemble vector of features\n",
    "assembler = VectorAssembler(inputCols=[x for x in weather.columns if x not in ignore_cols], outputCol='features')\n",
    "assembler.transform(weather)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[MinTemp: double, MaxTemp: double, Rainfall: double, WindGustDir: string, WindGustSpeed: double, WindDir9am: string, WindDir3pm: string, WindSpeed9am: double, WindSpeed3pm: double, Humidity9am: double, Humidity3pm: double, Pressure9am: double, Pressure3pm: double, RainToday: string, RainTomorrow: string, WindGustDirIndex: double, WindDir9amIndex: double, WindDir3pmIndex: double, RainTodayIndex: double, RainTomorrowIndex: double, features: vector]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# create a dataframe for feature vector and target variable\n",
    "df = assembler.transform(weather)\n",
    "# drop all columns except for features vector and RainTomorrowIndex\n",
    "df = df.select(['RainTomorrowIndex', 'features'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "df.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- RainTomorrowIndex: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df.show(5, False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+----------------------------------------------------------------------+\n",
      "|RainTomorrowIndex|features                                                              |\n",
      "+-----------------+----------------------------------------------------------------------+\n",
      "|0.0              |[13.4,22.9,0.6,44.0,20.0,24.0,71.0,22.0,1007.7,1007.1,0.0,6.0,7.0,0.0]|\n",
      "|0.0              |[7.4,25.1,0.0,44.0,4.0,22.0,44.0,25.0,1010.6,1007.8,9.0,9.0,3.0,0.0]  |\n",
      "|0.0              |[12.9,25.7,0.0,46.0,19.0,26.0,38.0,30.0,1007.6,1008.7,6.0,6.0,3.0,0.0]|\n",
      "|0.0              |[9.2,28.0,0.0,24.0,11.0,9.0,45.0,16.0,1017.6,1012.8,13.0,1.0,10.0,0.0]|\n",
      "|0.0              |[17.5,32.3,1.0,41.0,7.0,20.0,82.0,33.0,1010.8,1006.0,0.0,10.0,8.0,0.0]|\n",
      "+-----------------+----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Split dataset is randomly split into two parts, including 70% training data and 30% testing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# divide data into train sets and test sets. Seed is the value used to make the same data later\n",
    " \n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Dataset Count: 99626\n",
      "Test Dataset Count: 42567\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part C: Apply Machine Learning Algorithms\n",
    "### Step 8: Apply Machine Learning classification algorithms on the dataset and compare their accuracy. Plot the accuracy as bar graph\n",
    "- In this section, we are going to use some classification methods, including:\n",
    "    - DecisionTreeClassifier\n",
    "    - RandomForestClassifier\n",
    "    - LogisticRegression\n",
    "    - GBTClassifier\n",
    "- The purpose is calculate the probability of the rainfall tomorrow based on the other related data points\n",
    "- A graph is drawn to compare the accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DecisionTreeClassifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# build desicion tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"RainTomorrowIndex\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(train)\n",
    "\n",
    "# compute the target variable on test data\n",
    "dt_predictions = dt_model.transform(test)\n",
    "\n",
    "# show the first 5 results\n",
    "dt_predictions.select(\"RainTomorrowIndex\", \"rawPrediction\", \"probability\", \"prediction\").show(5)\n",
    "\n",
    "# check the accuracy of the model using MulticlassClassificationEvaluator\n",
    "# we can also use BinaryClassficationEvaluator here as our target variable is binary\n",
    "dt_evaluator = MulticlassClassificationEvaluator(\\\n",
    "labelCol=\"RainTomorrowIndex\", predictionCol=\"prediction\",\\\n",
    "metricName=\"accuracy\")\n",
    "\n",
    "# accuracy\n",
    "dt_accuracy = dt_evaluator.evaluate(dt_predictions)\n",
    "\n",
    "# print the results\n",
    "print(\"Test Error = %g \" % (1.0 - dt_accuracy))\n",
    "print(\"Accuracy = %g \" % dt_accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+----------------+--------------------+----------+\n",
      "|RainTomorrowIndex|   rawPrediction|         probability|prediction|\n",
      "+-----------------+----------------+--------------------+----------+\n",
      "|              0.0|[62519.0,8056.0]|[0.88585193057031...|       0.0|\n",
      "|              0.0|[62519.0,8056.0]|[0.88585193057031...|       0.0|\n",
      "|              0.0|[62519.0,8056.0]|[0.88585193057031...|       0.0|\n",
      "|              0.0| [2287.0,1104.0]|[0.67443232084930...|       0.0|\n",
      "|              0.0|[62519.0,8056.0]|[0.88585193057031...|       0.0|\n",
      "+-----------------+----------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.167877 \n",
      "Accuracy = 0.832123 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RandomForestClassifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# build the RandomForest model using built-in function\n",
    "rf = RandomForestClassifier(labelCol=\"RainTomorrowIndex\",\\\n",
    "featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# fit the model to train data\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "# compute target variable using the model on test data\n",
    "rf_predictions = rf_model.transform(test)\n",
    "\n",
    "# show the first 5 results\n",
    "rf_predictions.select(\"RainTomorrowIndex\", \"rawPrediction\", \"probability\", \"prediction\").show(5)\n",
    "\n",
    "# build Evaluator to check model accuracy\n",
    "rf_evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"RainTomorrowIndex\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# accuracy and print out\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - rf_accuracy))\n",
    "print(\"Accuracy  = %g\" % rf_accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+--------------------+--------------------+----------+\n",
      "|RainTomorrowIndex|       rawPrediction|         probability|prediction|\n",
      "+-----------------+--------------------+--------------------+----------+\n",
      "|              0.0|[8.43446363184703...|[0.84344636318470...|       0.0|\n",
      "|              0.0|[8.65873034893959...|[0.86587303489395...|       0.0|\n",
      "|              0.0|[8.43446363184703...|[0.84344636318470...|       0.0|\n",
      "|              0.0|[6.26335854942280...|[0.62633585494228...|       0.0|\n",
      "|              0.0|[8.53929775360288...|[0.85392977536028...|       0.0|\n",
      "+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.166162\n",
      "Accuracy  = 0.833838\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LogisticRegression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# create an initial logistic regression model using the train set.\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'RainTomorrowIndex', maxIter=10)\n",
    "\n",
    "# train model on training data\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# apply model to compute target variable on test data\n",
    "lr_predictions = lr_model.transform(test)\n",
    "\n",
    "# show the first 5 results\n",
    "lr_predictions.select(\"RainTomorrowIndex\", \"rawPrediction\", \"probability\", \"prediction\").show(5)\n",
    "\n",
    "# build Evaluator to check model accuracy\n",
    "lr_evaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrowIndex\",\\\n",
    "predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "\n",
    "# accurancy metric and print out\n",
    "lr_accuracy = lr_evaluator.evaluate(lr_predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - lr_accuracy))\n",
    "print(\"Accuracy  = %g\" % lr_accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+--------------------+--------------------+----------+\n",
      "|RainTomorrowIndex|       rawPrediction|         probability|prediction|\n",
      "+-----------------+--------------------+--------------------+----------+\n",
      "|              0.0|[1.14442644793282...|[0.75849141293276...|       0.0|\n",
      "|              0.0|[1.31710076552348...|[0.78869894504587...|       0.0|\n",
      "|              0.0|[0.99924324967793...|[0.73090976647295...|       0.0|\n",
      "|              0.0|[0.66993260033082...|[0.66148806712518...|       0.0|\n",
      "|              0.0|[0.95655274543752...|[0.72243107673444...|       0.0|\n",
      "+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.184768\n",
      "Accuracy  = 0.815232\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GBTClassifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# build the Gradient-Boosted Tree Classifier model using built-in function\n",
    "gbt = GBTClassifier(labelCol=\"RainTomorrowIndex\",featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# fit model to the train data\n",
    "gbt_model = gbt.fit(train)\n",
    "\n",
    "# apply model to compute target variable on test data\n",
    "gbt_predictions = gbt_model.transform(test)\n",
    "\n",
    "# show the first 5 results\n",
    "gbt_predictions.select(\"RainTomorrowIndex\", \"rawPrediction\", \"probability\", \"prediction\").show(5)\n",
    "\n",
    "# build Evaluator to check model accuracy\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrowIndex\",\\\n",
    "predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "\n",
    "# accurancy metric and print out\n",
    "gbt_accuracy = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - gbt_accuracy))\n",
    "print(\"Accuracy  = %g\" % gbt_accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+--------------------+--------------------+----------+\n",
      "|RainTomorrowIndex|       rawPrediction|         probability|prediction|\n",
      "+-----------------+--------------------+--------------------+----------+\n",
      "|              0.0|[0.715508419651,-...|[0.80705970166642...|       0.0|\n",
      "|              0.0|[0.71235011850945...|[0.80607420795204...|       0.0|\n",
      "|              0.0|[0.61846068335410...|[0.77502767900231...|       0.0|\n",
      "|              0.0|[0.05730146993490...|[0.52861941826497...|       0.0|\n",
      "|              0.0|[0.63887163865184...|[0.78206538744235...|       0.0|\n",
      "+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.160829\n",
      "Accuracy  = 0.839171\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparison of accuracy between all models\n",
    "- In this section, we are going to draw a bar plot for demonstrating accuracy rate of all four models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# prepare data\n",
    "accuracy = [dt_accuracy, rf_accuracy, lr_accuracy, gbt_accuracy]\n",
    "model_types = [\"Decision Tree\", \"Randon Forest\", \"Logistic \\nRegression\", \"Gradient \\nBoosted Tree\"]\n",
    "\n",
    "# plot\n",
    "bar_width = 0.5\n",
    "y_pos = np.arange(len(model_types))\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# change the limit of y-axis\n",
    "plt.ylim(0.8, 0.85)\n",
    "\n",
    "plt.bar(y_pos, accuracy, bar_width, align='center', color='C0')\n",
    "plt.xticks(y_pos, model_types)\n",
    "\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.title('Model Accuracy: A comparison between different classifier models')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> - In general, the four machine learning algorithms result in pretty impressive accuracy rates, ranging from 81% to almost 84%. In fact, there is no big difference between the models' performance\n",
    "- Decision Tree and Random Forest Classifier Models have quite similar accuracy rates of just above 83%\n",
    "- Gradient Boosted Tree Classifier performs the best in this problem (even though the distance to the second best model is miniscule), having accuracy rate of almost 84%\n",
    "- Logistic Regression Classifier has the lowest accuracy rate of arounf 81%. However, this performance metric is still great"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 9: Calculate the confusion matrix and find the precision, recall, and F1 score of each classification algorithm and explain how the accuracy of prediction can be improved\n",
    "- In this section, we are going to compute the confusion matrix to find precision, recall and F1 score for each model\n",
    "- Next, we are going to discuss how the accuracy of prediction can be improved"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def Metrics(df):\n",
    "    tp = df[(df.RainTomorrowIndex == 1.0) & (df.prediction == 1.0)].count()\n",
    "    tn = df[(df.RainTomorrowIndex == 0.0) & (df.prediction == 0.0)].count()\n",
    "    fp = df[(df.RainTomorrowIndex == 0.0) & (df.prediction == 1.0)].count()\n",
    "    fn = df[(df.RainTomorrowIndex == 1.0) & (df.prediction == 0.0)].count()\n",
    "    cm = [(\"True Possitive\", tp), (\"True Negative\", tn), (\"False Positive\", fp), (\"False Negative\", fn)]\n",
    "    precision = round(tp/(tp+fp),2)\n",
    "    recall = round(tp/(tp+fn),2)\n",
    "    f1 = round(2*((precision*recall)/(precision+recall)),2)\n",
    "    return (cm, precision, recall, f1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# We are going to extract the Prediction and Label for each algorithm\n",
    "\n",
    "# decision tree\n",
    "dt_df = dt_predictions.select([\"RainTomorrowIndex\",\"prediction\"])\n",
    "\n",
    "# random forest\n",
    "rf_df = rf_predictions.select([\"RainTomorrowIndex\",\"prediction\"])\n",
    "\n",
    "# logistic regression\n",
    "lr_df = lr_predictions.select([\"RainTomorrowIndex\",\"prediction\"])\n",
    "\n",
    "# GBT\n",
    "gbt_df = gbt_predictions.select([\"RainTomorrowIndex\",\"prediction\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics of Decision Tree Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Metrics of decision tree algorithm\n",
    "print(\"Metrics of Decision Tree Algorithm:\")\n",
    "# confusion matrix\n",
    "print(\"- Confusion Matrix:\\n\", Metrics(dt_df)[0])\n",
    "# precision\n",
    "print(\"- Precision: \", Metrics(dt_df)[1])\n",
    "# recall\n",
    "print(\"- Recall: \", Metrics(dt_df)[2])\n",
    "# F1\n",
    "print(\"- F1: \", Metrics(dt_df)[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics of Decision Tree Algorithm:\n",
      "- Confusion Matrix:\n",
      " [('True Possitive', 3570), ('True Negative', 31851), ('False Positive', 1207), ('False Negative', 5939)]\n",
      "- Precision:  0.75\n",
      "- Recall:  0.38\n",
      "- F1:  0.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics of Random Forest Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Metrics of random forest algorithm\n",
    "print(\"Metrics of Random Forest Algorithm:\")\n",
    "# confusion matrix\n",
    "print(\"- Confusion Matrix:\\n\", Metrics(rf_df)[0])\n",
    "# precision\n",
    "print(\"- Precision: \", Metrics(rf_df)[1])\n",
    "# recall\n",
    "print(\"- Recall: \", Metrics(rf_df)[2])\n",
    "# F1\n",
    "print(\"- F1: \", Metrics(rf_df)[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics of Random Forest Algorithm:\n",
      "- Confusion Matrix:\n",
      " [('True Possitive', 3497), ('True Negative', 31997), ('False Positive', 1061), ('False Negative', 6012)]\n",
      "- Precision:  0.77\n",
      "- Recall:  0.37\n",
      "- F1:  0.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics of Logistric Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Metrics of Logistic Regression algorithm\n",
    "print(\"Metrics of Logistic Regression Algorithm:\")\n",
    "# confusion matrix\n",
    "print(\"- Confusion Matrix:\\n\", Metrics(lr_df)[0])\n",
    "# precision\n",
    "print(\"- Precision: \", Metrics(lr_df)[1])\n",
    "# recall\n",
    "print(\"- Recall: \", Metrics(lr_df)[2])\n",
    "# F1\n",
    "print(\"- F1: \", Metrics(lr_df)[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics of Logistic Regression Algorithm:\n",
      "- Confusion Matrix:\n",
      " [('True Possitive', 3951), ('True Negative', 30751), ('False Positive', 2307), ('False Negative', 5558)]\n",
      "- Precision:  0.63\n",
      "- Recall:  0.42\n",
      "- F1:  0.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics of Gradient Boosted Trees Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Metrics of GBT algorithm\n",
    "print(\"Metrics of Gradient Boosted Trees Algorithm:\")\n",
    "# confusion matrix\n",
    "print(\"- Confusion Matrix:\\n\", Metrics(gbt_df)[0])\n",
    "# precision\n",
    "print(\"- Precision: \", Metrics(gbt_df)[1])\n",
    "# recall\n",
    "print(\"- Recall: \", Metrics(gbt_df)[2])\n",
    "# F1\n",
    "print(\"- F1: \", Metrics(gbt_df)[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics of Gradient Boosted Trees Algorithm:\n",
      "- Confusion Matrix:\n",
      " [('True Possitive', 4174), ('True Negative', 31547), ('False Positive', 1511), ('False Negative', 5335)]\n",
      "- Precision:  0.73\n",
      "- Recall:  0.44\n",
      "- F1:  0.55\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### How we can improve the accuracy of the prediction\n",
    "##### 1. Handling missing and outlier data\n",
    "    - In the previous step, we were dealing with missing data by imputing the average values for numeric variables and imputing the higest frequent items for non-numeric variables\n",
    "    - This might not be the most ideal method for handling missing data. For example, by replacing missing data with higest frequent items, the data is even more biased to the highest frequent items where it might not be true in real case\n",
    "    - First, we need to investigate why the data is gone missing and which type of missing for each variable, including Missing At Random (MAR), Missing Completely As Random (MCAR), and Missing Not At Random (MNAR)\n",
    "    - Second, after understanding the nature of missing, we should implement different methods on different kind of missing on each variable. For example: Mean, Median, Mode, Time Series, Linear Regression, etc.\n",
    "    - Outliers should also be detected and removed before going to the training dataset\n",
    "\n",
    "##### 2. Exploratory Data Analysis\n",
    "    - We should explore our dataset first by both descriptive statistics and visualisation to deeply understand the interaction between variables, etc.\n",
    "    - Gain insights about our dataset\n",
    "\n",
    "##### 3. Feature engineering and selection\n",
    "    - Here we haven't done a proper feature selection procedure\n",
    "    - In order to improve the accuracy of prediction, we should consider to implement\n",
    "        - Feature normalisation and transformation\n",
    "        - Removal of non-significant variables to the prediction model, i.e. the independent variables that have low impact on the dependent variable\n",
    "        - Stepwise methodology (forward, backward, hybrid)\n",
    "        - Inspect whether we have multicollinearity among variables and handle\n",
    "        - Removal of highly-correlated variable\n",
    "        - Create of new features from the insights of EDA (interactive features, etc.)\n",
    "\n",
    "##### 4. Cross-validation\n",
    "    - Usually, our prediction model is biased towards the training data\n",
    "    - Here we split the data into 70% and 30%, but we don't know which is the most ideal ratio and subsets\n",
    "    - Cross-validation method (such as k-folds) divides the dataset into k-parts and implement train and test model on each subset each time\n",
    "    - It helps to reduce bias of the model to the training data\n",
    "    \n",
    "#### 5. Other methods\n",
    "    - Algorithm tuning\n",
    "    - Ensemble methods\n",
    "    - etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This is the end of this assignment"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}